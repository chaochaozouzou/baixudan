{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying state of activity with acceleration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document, we want to evaluate performance of a one-dimensional convolutional network model on multiclass classification of activity using acceleration data, and compare with other models (logistic regression, svm, gradient boosting). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading/splitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document, we will compare performance of different models on activity classification with accelerations data. \n",
    "\n",
    "We will first load the data and the labels, and print first few lines of them to see that we have four different classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows of acceleration data: 2018\n",
      "\n",
      "first 5 lines of acceleration data:\n",
      "         1        2         3\n",
      "0  0.27203  1.00820 -0.082102\n",
      "1  0.27203  1.00820 -0.082102\n",
      "2  0.44791  0.91636 -0.013684\n",
      "3  0.44791  0.91636 -0.013684\n",
      "4  0.34238  0.96229 -0.059296\n",
      "\n",
      "first 5 lines of labels:\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: 8, dtype: int64\n",
      "\n",
      "classes:\n",
      "{1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv('data/motion1.csv',header=None)\n",
    "df2 = pd.read_csv('data/motion2.csv',header=None)\n",
    "df3 = pd.read_csv('data/motion3.csv',header=None)\n",
    "df4 = pd.read_csv('data/motion4.csv',header=None)\n",
    "df5 = pd.read_csv('data/motion5.csv',header=None)\n",
    "df = pd.concat([df1, df2, df3, df4, df5])\n",
    "print('# rows of acceleration data:', len(df))\n",
    "print('')\n",
    "acc_data = df.loc[:,1:3]\n",
    "lbl_data = df.loc[:,8]\n",
    "print('first 5 lines of acceleration data:')\n",
    "print(acc_data.head())\n",
    "print('')\n",
    "print('first 5 lines of labels:')\n",
    "print(lbl_data.head())\n",
    "print('')\n",
    "print('classes:')\n",
    "print(set(lbl_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then split the data and labels into training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(acc_data, lbl_data, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-dimensional convolutional network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by evaluating the performance of a 1d conv net on classifying this data. \n",
    "\n",
    "The 1d conv net is constructed as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# conv net\n",
    "cnn = keras.Sequential([\n",
    "    keras.layers.Conv1D(filters=100, kernel_size=2, input_shape=(None, 3), padding='same'), \n",
    "    keras.layers.Dropout(0.5), \n",
    "    #keras.layers.MaxPooling1D(2, padding='same'), \n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous document, we need to reshape our data and labels to appropriate dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.array(X_train)\n",
    "X_test_cnn = np.array(X_test)\n",
    "\n",
    "idx_train = [int(idx) for idx in y_train-1]\n",
    "idx_test = [int(idx) for idx in y_test-1]\n",
    "y_train_cnn = np.zeros((len(y_train), 4))\n",
    "y_train_cnn[np.arange(len(y_train)), idx_train] = 1\n",
    "y_test_cnn = np.zeros((len(y_test), 4))\n",
    "y_test_cnn[np.arange(len(y_test)), idx_test] = 1\n",
    "\n",
    "X_train_cnn = X_train_cnn.reshape(X_train_cnn.shape[0], 1, X_train_cnn.shape[1])\n",
    "X_test_cnn = X_test_cnn.reshape(X_test_cnn.shape[0], 1, X_test_cnn.shape[1])\n",
    "y_train_cnn = y_train_cnn.reshape(y_train_cnn.shape[0], 1, y_train_cnn.shape[1])\n",
    "y_test_cnn = y_test_cnn.reshape(y_test_cnn.shape[0], 1, y_test_cnn.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then evaluate the performance of our model with accuracy, precision-recall, and f-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 988 samples, validate on 424 samples\n",
      "Epoch 1/50\n",
      "988/988 [==============================] - 0s 278us/step - loss: 1.0640 - acc: 0.6802 - val_loss: 0.8557 - val_acc: 0.8137\n",
      "Epoch 2/50\n",
      "988/988 [==============================] - 0s 43us/step - loss: 0.7436 - acc: 0.8269 - val_loss: 0.6613 - val_acc: 0.8113\n",
      "Epoch 3/50\n",
      "988/988 [==============================] - 0s 35us/step - loss: 0.5987 - acc: 0.8259 - val_loss: 0.5623 - val_acc: 0.8137\n",
      "Epoch 4/50\n",
      "988/988 [==============================] - 0s 34us/step - loss: 0.5174 - acc: 0.8320 - val_loss: 0.5003 - val_acc: 0.8255\n",
      "Epoch 5/50\n",
      "988/988 [==============================] - 0s 34us/step - loss: 0.4672 - acc: 0.8330 - val_loss: 0.4607 - val_acc: 0.8302\n",
      "Epoch 6/50\n",
      "988/988 [==============================] - 0s 36us/step - loss: 0.4319 - acc: 0.8320 - val_loss: 0.4330 - val_acc: 0.8302\n",
      "Epoch 7/50\n",
      "988/988 [==============================] - ETA: 0s - loss: 0.5948 - acc: 0.750 - 0s 34us/step - loss: 0.4016 - acc: 0.8350 - val_loss: 0.4132 - val_acc: 0.8302\n",
      "Epoch 8/50\n",
      "988/988 [==============================] - 0s 34us/step - loss: 0.3880 - acc: 0.8391 - val_loss: 0.3972 - val_acc: 0.8302\n",
      "Epoch 9/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.3721 - acc: 0.8391 - val_loss: 0.3848 - val_acc: 0.8255\n",
      "Epoch 10/50\n",
      "988/988 [==============================] - 0s 34us/step - loss: 0.3606 - acc: 0.8532 - val_loss: 0.3736 - val_acc: 0.8396\n",
      "Epoch 11/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.3467 - acc: 0.8603 - val_loss: 0.3648 - val_acc: 0.8420\n",
      "Epoch 12/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.3365 - acc: 0.8674 - val_loss: 0.3569 - val_acc: 0.8373\n",
      "Epoch 13/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.3292 - acc: 0.8674 - val_loss: 0.3501 - val_acc: 0.8632\n",
      "Epoch 14/50\n",
      "988/988 [==============================] - 0s 30us/step - loss: 0.3184 - acc: 0.8684 - val_loss: 0.3441 - val_acc: 0.8585\n",
      "Epoch 15/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.3123 - acc: 0.8826 - val_loss: 0.3388 - val_acc: 0.8585\n",
      "Epoch 16/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.3019 - acc: 0.8877 - val_loss: 0.3338 - val_acc: 0.8585\n",
      "Epoch 17/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.3026 - acc: 0.8887 - val_loss: 0.3294 - val_acc: 0.8585\n",
      "Epoch 18/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.3006 - acc: 0.8856 - val_loss: 0.3257 - val_acc: 0.8585\n",
      "Epoch 19/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2829 - acc: 0.8968 - val_loss: 0.3229 - val_acc: 0.8608\n",
      "Epoch 20/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2881 - acc: 0.9008 - val_loss: 0.3194 - val_acc: 0.8703\n",
      "Epoch 21/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2834 - acc: 0.8887 - val_loss: 0.3176 - val_acc: 0.8608\n",
      "Epoch 22/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2807 - acc: 0.8947 - val_loss: 0.3149 - val_acc: 0.8726\n",
      "Epoch 23/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2672 - acc: 0.9059 - val_loss: 0.3130 - val_acc: 0.8750\n",
      "Epoch 24/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2688 - acc: 0.8947 - val_loss: 0.3115 - val_acc: 0.8868\n",
      "Epoch 25/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2666 - acc: 0.8998 - val_loss: 0.3105 - val_acc: 0.8844\n",
      "Epoch 26/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.2616 - acc: 0.9059 - val_loss: 0.3091 - val_acc: 0.9057\n",
      "Epoch 27/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.2659 - acc: 0.9109 - val_loss: 0.3082 - val_acc: 0.9033\n",
      "Epoch 28/50\n",
      "988/988 [==============================] - 0s 30us/step - loss: 0.2533 - acc: 0.9069 - val_loss: 0.3071 - val_acc: 0.9057\n",
      "Epoch 29/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2695 - acc: 0.9069 - val_loss: 0.3078 - val_acc: 0.9057\n",
      "Epoch 30/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2527 - acc: 0.9119 - val_loss: 0.3061 - val_acc: 0.9057\n",
      "Epoch 31/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2602 - acc: 0.9049 - val_loss: 0.3065 - val_acc: 0.9057\n",
      "Epoch 32/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2556 - acc: 0.9140 - val_loss: 0.3061 - val_acc: 0.9057\n",
      "Epoch 33/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2486 - acc: 0.9140 - val_loss: 0.3058 - val_acc: 0.9057\n",
      "Epoch 34/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2485 - acc: 0.9109 - val_loss: 0.3049 - val_acc: 0.9033\n",
      "Epoch 35/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.2591 - acc: 0.9140 - val_loss: 0.3050 - val_acc: 0.9033\n",
      "Epoch 36/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2496 - acc: 0.9099 - val_loss: 0.3047 - val_acc: 0.9057\n",
      "Epoch 37/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.2447 - acc: 0.9160 - val_loss: 0.3058 - val_acc: 0.9033\n",
      "Epoch 38/50\n",
      "988/988 [==============================] - 0s 34us/step - loss: 0.2493 - acc: 0.9160 - val_loss: 0.3047 - val_acc: 0.9033\n",
      "Epoch 39/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2437 - acc: 0.9140 - val_loss: 0.3044 - val_acc: 0.9033\n",
      "Epoch 40/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2419 - acc: 0.9221 - val_loss: 0.3047 - val_acc: 0.9033\n",
      "Epoch 41/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2476 - acc: 0.9150 - val_loss: 0.3059 - val_acc: 0.9033\n",
      "Epoch 42/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.2488 - acc: 0.9099 - val_loss: 0.3057 - val_acc: 0.9033\n",
      "Epoch 43/50\n",
      "988/988 [==============================] - 0s 32us/step - loss: 0.2477 - acc: 0.9140 - val_loss: 0.3048 - val_acc: 0.9033\n",
      "Epoch 44/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.2414 - acc: 0.9160 - val_loss: 0.3061 - val_acc: 0.9033\n",
      "Epoch 45/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2395 - acc: 0.9261 - val_loss: 0.3058 - val_acc: 0.9033\n",
      "Epoch 46/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.2407 - acc: 0.9140 - val_loss: 0.3049 - val_acc: 0.9033\n",
      "Epoch 47/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.2406 - acc: 0.9160 - val_loss: 0.3053 - val_acc: 0.9033\n",
      "Epoch 48/50\n",
      "988/988 [==============================] - 0s 30us/step - loss: 0.2500 - acc: 0.9221 - val_loss: 0.3046 - val_acc: 0.9033\n",
      "Epoch 49/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.2425 - acc: 0.9170 - val_loss: 0.3046 - val_acc: 0.9033\n",
      "Epoch 50/50\n",
      "988/988 [==============================] - 0s 31us/step - loss: 0.2367 - acc: 0.9190 - val_loss: 0.3053 - val_acc: 0.9033\n",
      "606/606 [==============================] - 0s 10us/step\n",
      "1d conv net results:\n",
      "loss: 0.24605347122689677\n",
      "accuracy: 0.9092409229121192\n",
      "precision for 4 classes: [0.77486911 0.88679245 1.         0.64705882]\n",
      "recall for 4 classes: [0.925      0.75806452 1.         0.28205128]\n",
      "f1-score for 4 classes: [0.84330484 0.8173913  1.         0.39285714]\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(X_train_cnn, y_train_cnn, validation_split=0.3, epochs=50)\n",
    "loss, acc = cnn.evaluate(X_test_cnn, y_test_cnn)\n",
    "print('1d conv net results:')\n",
    "print('loss:', loss)\n",
    "print('accuracy:', acc)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "y_pred_cnn_test = cnn.predict(X_test_cnn)\n",
    "y_pred_cnn_test = np.argmax(y_pred_cnn_test, axis=2)\n",
    "y_pred_cnn_test = [row[0] for row in (y_pred_cnn_test+1)]\n",
    "print('precision for 4 classes:', precision_score(y_test, y_pred_cnn_test, average=None))\n",
    "print('recall for 4 classes:', recall_score(y_test, y_pred_cnn_test, average=None))\n",
    "print('f1-score for 4 classes:', f1_score(y_test, y_pred_cnn_test, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network has about 91% accuracy, high precision-recall rates for the first 3 classes, but lower precision-recall rates for class 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important for us to run other models on the same data to interpret the results of the 1d conv net. \n",
    "\n",
    "We will first run logistic regression and svm on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression results:\n",
      "accuracy 0.8712871287128713\n",
      "precision for 4 classes: [0.67521368 1.         1.         0.5       ]\n",
      "recall for 4 classes: [0.9875     0.37096774 1.         0.05128205]\n",
      "f1-score for 4 classes: [0.80203046 0.54117647 1.         0.09302326]\n",
      "\n",
      "svm results:\n",
      "accuracy 0.8811881188118812\n",
      "precision for 4 classes: [0.70183486 0.85714286 0.99710983 0.        ]\n",
      "recall for 4 classes: [0.95625    0.58064516 1.         0.        ]\n",
      "f1-score for 4 classes: [0.80952381 0.69230769 0.99855282 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "print('logistic regression results:')\n",
    "print('accuracy', accuracy_score(y_test, lr.predict(X_test)))\n",
    "print('precision for 4 classes:', precision_score(y_test, lr.predict(X_test), average=None))\n",
    "print('recall for 4 classes:', recall_score(y_test, lr.predict(X_test), average=None))\n",
    "print('f1-score for 4 classes:', f1_score(y_test, lr.predict(X_test), average=None))\n",
    "print('')\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "sv = SVC().fit(X_train, y_train)\n",
    "print('svm results:')\n",
    "print('accuracy', accuracy_score(y_test, sv.predict(X_test)))\n",
    "print('precision for 4 classes:', precision_score(y_test, sv.predict(X_test), average=None))\n",
    "print('recall for 4 classes:', recall_score(y_test, sv.predict(X_test), average=None))\n",
    "print('f1-score for 4 classes:', f1_score(y_test, sv.predict(X_test), average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these models have only slightly lower accuracies, the precision-recall rates are much worse. \n",
    "\n",
    "We will now try the gradient boosting classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient boosting results:\n",
      "accuracy 0.9620462046204621\n",
      "precision for 4 classes: [0.89714286 0.93333333 1.         0.96296296]\n",
      "recall for 4 classes: [0.98125    0.90322581 0.99710145 0.66666667]\n",
      "f1-score for 4 classes: [0.93731343 0.91803279 0.99854862 0.78787879]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "print('gradient boosting results:')\n",
    "print('accuracy', accuracy_score(y_test, gb.predict(X_test)))\n",
    "print('precision for 4 classes:', precision_score(y_test, gb.predict(X_test), average=None))\n",
    "print('recall for 4 classes:', recall_score(y_test, gb.predict(X_test), average=None))\n",
    "print('f1-score for 4 classes:', f1_score(y_test, gb.predict(X_test), average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosting classifier works really well in this set up, with higher accuracy of about 96% and very good precision-recall rates. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
