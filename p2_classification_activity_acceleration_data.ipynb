{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying state of activity with acceleration data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document, we want to evaluate performance of a one-dimensional convolutional network model on multiclass classification of activity using acceleration data, and compare with other models (logistic regression, svm, gradient boosting). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading/splitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used for classification is first few files from 'Activity recognition with healthy older people using a batteryless wearable sensor Data Set' found on UCI Machine Learning Repository. The main reason why this data is selected for evaluating conv net is because it's sequential: the idea of convolutional networks build on the hypothesis that high-level features can be extracted from rows of data that lie close to each other, so it's important for our training data to be ordered. \n",
    "\n",
    "We will first load the data and the labels, and print first few lines of them to see that we have four different classes, and that our data is heavily skewed with smaller percentages of data of class 2 and class 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows of acceleration data: 2018\n",
      "\n",
      "first 5 lines of acceleration data:\n",
      "         1        2         3\n",
      "0  0.27203  1.00820 -0.082102\n",
      "1  0.27203  1.00820 -0.082102\n",
      "2  0.44791  0.91636 -0.013684\n",
      "3  0.44791  0.91636 -0.013684\n",
      "4  0.34238  0.96229 -0.059296\n",
      "\n",
      "first 5 lines of labels:\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: 8, dtype: int64\n",
      "\n",
      "classes:\n",
      "{1, 2, 3, 4}\n",
      "precentage of class 1: 0.2700693756194252\n",
      "precentage of class 2: 0.10802775024777007\n",
      "precentage of class 3: 0.568384539147671\n",
      "precentage of class 4: 0.053518334985133795\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_csv('data/motion1.csv',header=None)\n",
    "df2 = pd.read_csv('data/motion2.csv',header=None)\n",
    "df3 = pd.read_csv('data/motion3.csv',header=None)\n",
    "df4 = pd.read_csv('data/motion4.csv',header=None)\n",
    "df5 = pd.read_csv('data/motion5.csv',header=None)\n",
    "df = pd.concat([df1, df2, df3, df4, df5])\n",
    "print('# rows of acceleration data:', len(df))\n",
    "print('')\n",
    "acc_data = df.loc[:,1:3]\n",
    "lbl_data = df.loc[:,8]\n",
    "print('first 5 lines of acceleration data:')\n",
    "print(acc_data.head())\n",
    "print('')\n",
    "print('first 5 lines of labels:')\n",
    "print(lbl_data.head())\n",
    "print('')\n",
    "print('classes:')\n",
    "print(set(lbl_data))\n",
    "l = list(lbl_data)\n",
    "print('precentage of class 1:', len([thing for thing in l if thing==1])/len(l))\n",
    "print('precentage of class 2:', len([thing for thing in l if thing==2])/len(l))\n",
    "print('precentage of class 3:', len([thing for thing in l if thing==3])/len(l))\n",
    "print('precentage of class 4:', len([thing for thing in l if thing==4])/len(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then split the data and labels into training and testing sets. Note that it's important for us to not shuffle the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(acc_data, lbl_data, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-dimensional convolutional network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by evaluating the performance of a 1d conv net on classifying this data. \n",
    "\n",
    "The 1d conv net is constructed as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# conv net\n",
    "cnn = keras.Sequential([\n",
    "    keras.layers.Conv1D(filters=100, kernel_size=2, input_shape=(None, 3), padding='same'), \n",
    "    keras.layers.MaxPooling1D(2, padding='same'), \n",
    "    keras.layers.Dropout(0.5), \n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous document, we need to reshape our data and labels to appropriate dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cnn = np.array(X_train)\n",
    "X_test_cnn = np.array(X_test)\n",
    "\n",
    "idx_train = [int(idx) for idx in y_train-1]\n",
    "idx_test = [int(idx) for idx in y_test-1]\n",
    "y_train_cnn = np.zeros((len(y_train), 4))\n",
    "y_train_cnn[np.arange(len(y_train)), idx_train] = 1\n",
    "y_test_cnn = np.zeros((len(y_test), 4))\n",
    "y_test_cnn[np.arange(len(y_test)), idx_test] = 1\n",
    "\n",
    "X_train_cnn = X_train_cnn.reshape(X_train_cnn.shape[0], 1, X_train_cnn.shape[1])\n",
    "X_test_cnn = X_test_cnn.reshape(X_test_cnn.shape[0], 1, X_test_cnn.shape[1])\n",
    "y_train_cnn = y_train_cnn.reshape(y_train_cnn.shape[0], 1, y_train_cnn.shape[1])\n",
    "y_test_cnn = y_test_cnn.reshape(y_test_cnn.shape[0], 1, y_test_cnn.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then evaluate the performance of our model with accuracy, precision-recall, and f-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 988 samples, validate on 424 samples\n",
      "Epoch 1/50\n",
      "988/988 [==============================] - 0s 460us/step - loss: 1.1529 - acc: 0.5749 - val_loss: 1.0767 - val_acc: 0.4222\n",
      "Epoch 2/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.8503 - acc: 0.6862 - val_loss: 0.8880 - val_acc: 0.8042\n",
      "Epoch 3/50\n",
      "988/988 [==============================] - 0s 36us/step - loss: 0.6867 - acc: 0.7571 - val_loss: 0.7422 - val_acc: 0.8302\n",
      "Epoch 4/50\n",
      "988/988 [==============================] - 0s 36us/step - loss: 0.5978 - acc: 0.7733 - val_loss: 0.6595 - val_acc: 0.8302\n",
      "Epoch 5/50\n",
      "988/988 [==============================] - 0s 35us/step - loss: 0.5362 - acc: 0.7814 - val_loss: 0.5949 - val_acc: 0.8302\n",
      "Epoch 6/50\n",
      "988/988 [==============================] - 0s 36us/step - loss: 0.4952 - acc: 0.7915 - val_loss: 0.5598 - val_acc: 0.8491\n",
      "Epoch 7/50\n",
      "988/988 [==============================] - 0s 33us/step - loss: 0.4678 - acc: 0.8057 - val_loss: 0.5362 - val_acc: 0.8821\n",
      "Epoch 8/50\n",
      "988/988 [==============================] - 0s 40us/step - loss: 0.4465 - acc: 0.8269 - val_loss: 0.5167 - val_acc: 0.9080\n",
      "Epoch 9/50\n",
      "988/988 [==============================] - 0s 37us/step - loss: 0.4286 - acc: 0.8451 - val_loss: 0.4992 - val_acc: 0.9104\n",
      "Epoch 10/50\n",
      "988/988 [==============================] - 0s 36us/step - loss: 0.4138 - acc: 0.8401 - val_loss: 0.4838 - val_acc: 0.9198\n",
      "Epoch 11/50\n",
      "988/988 [==============================] - 0s 37us/step - loss: 0.4031 - acc: 0.8543 - val_loss: 0.4731 - val_acc: 0.9198\n",
      "Epoch 12/50\n",
      "988/988 [==============================] - 0s 38us/step - loss: 0.3883 - acc: 0.8613 - val_loss: 0.4578 - val_acc: 0.9222\n",
      "Epoch 13/50\n",
      "988/988 [==============================] - 0s 40us/step - loss: 0.3849 - acc: 0.8623 - val_loss: 0.4531 - val_acc: 0.9222\n",
      "Epoch 14/50\n",
      "988/988 [==============================] - 0s 35us/step - loss: 0.3785 - acc: 0.8583 - val_loss: 0.4329 - val_acc: 0.9222\n",
      "Epoch 15/50\n",
      "988/988 [==============================] - 0s 38us/step - loss: 0.3779 - acc: 0.8573 - val_loss: 0.4302 - val_acc: 0.9222\n",
      "Epoch 16/50\n",
      "988/988 [==============================] - 0s 42us/step - loss: 0.3668 - acc: 0.8654 - val_loss: 0.4277 - val_acc: 0.9222\n",
      "Epoch 17/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.3566 - acc: 0.8704 - val_loss: 0.4082 - val_acc: 0.9222\n",
      "Epoch 18/50\n",
      "988/988 [==============================] - 0s 42us/step - loss: 0.3609 - acc: 0.8694 - val_loss: 0.4164 - val_acc: 0.9175\n",
      "Epoch 19/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.3543 - acc: 0.8725 - val_loss: 0.3886 - val_acc: 0.9222\n",
      "Epoch 20/50\n",
      "988/988 [==============================] - 0s 40us/step - loss: 0.3494 - acc: 0.8694 - val_loss: 0.4095 - val_acc: 0.9222\n",
      "Epoch 21/50\n",
      "988/988 [==============================] - 0s 40us/step - loss: 0.3569 - acc: 0.8755 - val_loss: 0.3855 - val_acc: 0.9175\n",
      "Epoch 22/50\n",
      "988/988 [==============================] - 0s 43us/step - loss: 0.3414 - acc: 0.8826 - val_loss: 0.3867 - val_acc: 0.9104\n",
      "Epoch 23/50\n",
      "988/988 [==============================] - 0s 40us/step - loss: 0.3426 - acc: 0.8796 - val_loss: 0.3795 - val_acc: 0.9175\n",
      "Epoch 24/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.3450 - acc: 0.8806 - val_loss: 0.3759 - val_acc: 0.9175\n",
      "Epoch 25/50\n",
      "988/988 [==============================] - 0s 39us/step - loss: 0.3401 - acc: 0.8745 - val_loss: 0.3761 - val_acc: 0.9104\n",
      "Epoch 26/50\n",
      "988/988 [==============================] - 0s 38us/step - loss: 0.3405 - acc: 0.8806 - val_loss: 0.3802 - val_acc: 0.9175\n",
      "Epoch 27/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.3441 - acc: 0.8725 - val_loss: 0.3763 - val_acc: 0.9104\n",
      "Epoch 28/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.3263 - acc: 0.8856 - val_loss: 0.3728 - val_acc: 0.9127\n",
      "Epoch 29/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.3379 - acc: 0.8816 - val_loss: 0.3682 - val_acc: 0.9127\n",
      "Epoch 30/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.3287 - acc: 0.8745 - val_loss: 0.3556 - val_acc: 0.9127\n",
      "Epoch 31/50\n",
      "988/988 [==============================] - 0s 39us/step - loss: 0.3250 - acc: 0.8877 - val_loss: 0.3604 - val_acc: 0.9127\n",
      "Epoch 32/50\n",
      "988/988 [==============================] - 0s 38us/step - loss: 0.3292 - acc: 0.8775 - val_loss: 0.3498 - val_acc: 0.9127\n",
      "Epoch 33/50\n",
      "988/988 [==============================] - 0s 37us/step - loss: 0.3334 - acc: 0.8765 - val_loss: 0.3584 - val_acc: 0.9127\n",
      "Epoch 34/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.3207 - acc: 0.8907 - val_loss: 0.3466 - val_acc: 0.9127\n",
      "Epoch 35/50\n",
      "988/988 [==============================] - 0s 39us/step - loss: 0.3344 - acc: 0.8836 - val_loss: 0.3474 - val_acc: 0.9222\n",
      "Epoch 36/50\n",
      "988/988 [==============================] - 0s 39us/step - loss: 0.3301 - acc: 0.8826 - val_loss: 0.3548 - val_acc: 0.9127\n",
      "Epoch 37/50\n",
      "988/988 [==============================] - 0s 38us/step - loss: 0.3373 - acc: 0.8816 - val_loss: 0.3420 - val_acc: 0.9222\n",
      "Epoch 38/50\n",
      "988/988 [==============================] - 0s 41us/step - loss: 0.3276 - acc: 0.8887 - val_loss: 0.3502 - val_acc: 0.9222\n",
      "Epoch 39/50\n",
      "988/988 [==============================] - 0s 40us/step - loss: 0.3269 - acc: 0.8877 - val_loss: 0.3535 - val_acc: 0.9222\n",
      "Epoch 40/50\n",
      "988/988 [==============================] - 0s 39us/step - loss: 0.3238 - acc: 0.8957 - val_loss: 0.3402 - val_acc: 0.9222\n",
      "Epoch 41/50\n",
      "988/988 [==============================] - 0s 39us/step - loss: 0.3243 - acc: 0.8846 - val_loss: 0.3470 - val_acc: 0.9222\n",
      "Epoch 42/50\n",
      "988/988 [==============================] - 0s 39us/step - loss: 0.3277 - acc: 0.8887 - val_loss: 0.3523 - val_acc: 0.9222\n",
      "Epoch 43/50\n",
      "988/988 [==============================] - 0s 39us/step - loss: 0.3162 - acc: 0.8917 - val_loss: 0.3389 - val_acc: 0.9222\n",
      "Epoch 44/50\n",
      "988/988 [==============================] - 0s 38us/step - loss: 0.3289 - acc: 0.8866 - val_loss: 0.3317 - val_acc: 0.9222\n",
      "Epoch 45/50\n",
      "988/988 [==============================] - 0s 39us/step - loss: 0.3188 - acc: 0.8846 - val_loss: 0.3384 - val_acc: 0.9222\n",
      "Epoch 46/50\n",
      "988/988 [==============================] - 0s 38us/step - loss: 0.3206 - acc: 0.8897 - val_loss: 0.3348 - val_acc: 0.9222\n",
      "Epoch 47/50\n",
      "988/988 [==============================] - 0s 36us/step - loss: 0.3173 - acc: 0.8887 - val_loss: 0.3189 - val_acc: 0.9222\n",
      "Epoch 48/50\n",
      "988/988 [==============================] - 0s 36us/step - loss: 0.3192 - acc: 0.8877 - val_loss: 0.3491 - val_acc: 0.9222\n",
      "Epoch 49/50\n",
      "988/988 [==============================] - 0s 35us/step - loss: 0.3211 - acc: 0.8998 - val_loss: 0.3295 - val_acc: 0.9222\n",
      "Epoch 50/50\n",
      "988/988 [==============================] - 0s 38us/step - loss: 0.3217 - acc: 0.8897 - val_loss: 0.3442 - val_acc: 0.9222\n",
      "606/606 [==============================] - 0s 12us/step\n",
      "1d conv net results:\n",
      "loss: 0.2004010157779523\n",
      "accuracy: 0.9471947200620922\n",
      "precision for 4 classes: [0.90983607 0.66666667 1.         0.57142857]\n",
      "recall for 4 classes: [0.84090909 1.         1.         0.26666667]\n",
      "f1-score for 4 classes: [0.87401575 0.8        1.         0.36363636]\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(X_train_cnn, y_train_cnn, validation_split=0.3, epochs=50)\n",
    "loss, acc = cnn.evaluate(X_test_cnn, y_test_cnn)\n",
    "print('1d conv net results:')\n",
    "print('loss:', loss)\n",
    "print('accuracy:', acc)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "y_pred_cnn_test = cnn.predict(X_test_cnn)\n",
    "y_pred_cnn_test = np.argmax(y_pred_cnn_test, axis=2)\n",
    "y_pred_cnn_test = [row[0] for row in (y_pred_cnn_test+1)]\n",
    "print('precision for 4 classes:', precision_score(y_test, y_pred_cnn_test, average=None))\n",
    "print('recall for 4 classes:', recall_score(y_test, y_pred_cnn_test, average=None))\n",
    "print('f1-score for 4 classes:', f1_score(y_test, y_pred_cnn_test, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network has about 94.7% accuracy, high precision-recall rates for the first 3 classes, but lower precision-recall rates for class 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important for us to run other models on the same data to interpret the results of the 1d conv net. \n",
    "\n",
    "We will first run logistic regression and svm on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression results:\n",
      "accuracy 0.9026402640264026\n",
      "precision for 4 classes: [0.71856287 0.         1.         1.        ]\n",
      "recall for 4 classes: [0.90909091 0.         1.         0.26666667]\n",
      "f1-score for 4 classes: [0.80267559 0.         1.         0.42105263]\n",
      "\n",
      "svm results:\n",
      "accuracy 0.8976897689768977\n",
      "precision for 4 classes: [0.70588235 0.07692308 1.         0.        ]\n",
      "recall for 4 classes: [0.90909091 0.02777778 1.         0.        ]\n",
      "f1-score for 4 classes: [0.79470199 0.04081633 1.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\xudanb\\AppData\\Local\\Continuum\\anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "print('logistic regression results:')\n",
    "print('accuracy', accuracy_score(y_test, lr.predict(X_test)))\n",
    "print('precision for 4 classes:', precision_score(y_test, lr.predict(X_test), average=None))\n",
    "print('recall for 4 classes:', recall_score(y_test, lr.predict(X_test), average=None))\n",
    "print('f1-score for 4 classes:', f1_score(y_test, lr.predict(X_test), average=None))\n",
    "print('')\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "sv = SVC().fit(X_train, y_train)\n",
    "print('svm results:')\n",
    "print('accuracy', accuracy_score(y_test, sv.predict(X_test)))\n",
    "print('precision for 4 classes:', precision_score(y_test, sv.predict(X_test), average=None))\n",
    "print('recall for 4 classes:', recall_score(y_test, sv.predict(X_test), average=None))\n",
    "print('f1-score for 4 classes:', f1_score(y_test, sv.predict(X_test), average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models have only slightly lower accuracies than the conv net we constructed. \n",
    "\n",
    "We will now try the gradient boosting classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient boosting results:\n",
      "accuracy 0.9521452145214522\n",
      "precision for 4 classes: [0.96031746 0.74193548 1.         0.38461538]\n",
      "recall for 4 classes: [0.91666667 0.63888889 1.         0.66666667]\n",
      "f1-score for 4 classes: [0.9379845  0.68656716 1.         0.48780488]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "print('gradient boosting results:')\n",
    "print('accuracy', accuracy_score(y_test, gb.predict(X_test)))\n",
    "print('precision for 4 classes:', precision_score(y_test, gb.predict(X_test), average=None))\n",
    "print('recall for 4 classes:', recall_score(y_test, gb.predict(X_test), average=None))\n",
    "print('f1-score for 4 classes:', f1_score(y_test, gb.predict(X_test), average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosting classifier has slightly better accuracy, and better precision-recall rates than our conv net. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
